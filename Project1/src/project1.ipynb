{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from features_engineering import augment\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "import pickle as pkl\n",
    "import yaml\n",
    "from cross_validation import cross_validation_ridge\n",
    "from features_engineering import augment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parameters.yaml\") as f:\n",
    "    params = yaml.load(f, Loader=yaml.FullLoader)\n",
    "COMBINED_DEGREES = params['COMBINED_DEGREES']\n",
    "SIMPLE_DEGREES = params['SIMPLE_DEGREES']\n",
    "TAN_HYP_DEGREES = params['TAN_HYP_DEGREES']\n",
    "INVERSE_LOG_DEGREES = params['INVERSE_LOG_DEGREES']\n",
    "ROOT_DEGREES = params['ROOT_DEGREES']\n",
    "NUM_SETS = params['NUM_SETS']\n",
    "DATA_TRAIN_PATH = params['DATA_TRAIN_PATH']\n",
    "DATA_TEST_PATH = params['DATA_TEST_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y, tX_train, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x)\n",
    "    x = x / std_x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 2\n",
      "Degree 3\n",
      "Adding simple powers [4-5]\n",
      "Adding tanh powers\n",
      "Adding simple powers [2-10]\n",
      "Adding tanh powers\n",
      "Adding simple powers [2-10]\n",
      "Adding tanh powers\n"
     ]
    }
   ],
   "source": [
    "(xs_train, masks_train) = preprocessing(tX_train)\n",
    "(xs_test, masks_test) = preprocessing(tX_test)\n",
    "xs_train_aug = []\n",
    "xs_test_aug = []\n",
    "for i in range(NUM_SETS):\n",
    "    xs_train_aug.append(augment(xs_train[i], \n",
    "                          COMBINED_DEGREES[i], \n",
    "                          SIMPLE_DEGREES[i], \n",
    "                          TAN_HYP_DEGREES[i], \n",
    "                          INVERSE_LOG_DEGREES[i], \n",
    "                          ROOT_DEGREES[i]))\n",
    "#     xs_test_aug.append(augment(xs_test[i], \n",
    "#                       COMBINED_DEGREES[i], \n",
    "#                       SIMPLE_DEGREES[i], \n",
    "#                       TAN_HYP_DEGREES[i], \n",
    "#                       INVERSE_LOG_DEGREES[i], \n",
    "#                       ROOT_DEGREES[i]))\n",
    "# y=y[:,np.newaxis]\n",
    "# y_logistic=(y+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_len=tX_test.shape[0]\n",
    "# lq=lambda a,b,c,d,e,f:least_squares(a,b)\n",
    "# lqgd=lambda a,b,c,d,e,f: least_squares_GD(a, b, d, e, f)\n",
    "# lqsgd=lambda a,b,c,d,e,f: least_squares_SGD(a, b, d, e, f)\n",
    "# r=lambda a,b,c,d,e,f: ridge_regression(a, b, c)\n",
    "# lgd=lambda a,b,c,d,e,f: logistic_regression_GD(a,b,d,e,f)\n",
    "# lsgd=lambda a,b,c,d,e,f: logistic_regression_SGD(a,b,d,e,f)\n",
    "# rlgd=reg_logistic_regression_GD\n",
    "# rlsgd=reg_logistic_regression_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet Num = 2\n",
      "1e-05 0.8236421284808382\n",
      "1.623776739188721e-05 0.8227874276261373\n",
      "2.6366508987303556e-05 0.8208712434518886\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-27d47caf5061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation_ridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmasks_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_train_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfull_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/battleman/CLOUX_64/EPFL/2019-2020/Autumn/ML/Space-ML/Project1/src/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation_ridge\u001b[0;34m(y_train, x_train, num_folds, lambda_, seed)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_train_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_sub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_fold_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0my_val_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_predict\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_val_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/battleman/CLOUX_64/EPFL/2019-2020/Autumn/ML/Space-ML/Project1/src/implementations.py\u001b[0m in \u001b[0;36mridge_regression\u001b[0;34m(y, tx, lambda_)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m\"\"\"applies ridge regression to optimize w\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mlambdaI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambdaI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-5, -1, 20) \n",
    "full_accuracies = []\n",
    "for i in range(2,3):\n",
    "    print(\"Jet Num = {}\".format(i))\n",
    "    accuracies = []\n",
    "    for l in lambdas:\n",
    "        accuracies.append(np.mean(cross_validation_ridge(y[masks_train[i]], xs_train_aug[i], 10, l)))\n",
    "        print(l, accuracies[-1])\n",
    "    full_accuracies.append(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3, 1, 1, sharex=True)\n",
    "plt.plot(lambdas, full_accuracies[0], 'o-')\n",
    "\n",
    "plt.subplot(3, 1, 2, sharex=True)\n",
    "plt.plot(lambdas, full_accuracies[1], '.-')\n",
    "\n",
    "plt.subplot(3,1,3, sharex=True)\n",
    "plt.plot(lambdas, full_accuracies[2], '*-')\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_val(y,x,p,reg_f):\n",
    "#     d=len(y)\n",
    "#     rand_ind = np.random.permutation(d)\n",
    "#     cut = int(p*d) # where to cut train/validation\n",
    "#     x_train, y_train = x[rand_ind][:cut], y[rand_ind][:cut]\n",
    "#     x_val, y_val = x[rand_ind][cut:], y[rand_ind][cut:]\n",
    "    \n",
    "#     (xs_train, masks_train) = preprocessing(x_train)\n",
    "#     (xs_val, masks_val) = preprocessing(x_val)\n",
    "#     ytrl=np.where(ytr==-1,0,1)\n",
    "#     # Logistic Or Not\n",
    "#     ys=[ytrl if logis else ytr for logis in logistics]\n",
    "#     y_bar=predictions(ytr,ys, xstr, xste, mtr, mte, reg_fs, len(yte), degrees, lambdas, max_iters, gammas, logistics)\n",
    "#     yte[yte==0]=-1\n",
    "#     print(np.sum((yte==y_bar))/len(yte))\n",
    "\n",
    "    \n",
    "# basic_cross(y,tX_train,0.8,reg_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# OUTPUT_PATH = '../predictions.csv' # TODO: fill in desired name of output file for submission\n",
    "# # y_pred = predict_labels(weights, tX_test)\n",
    "# create_csv_submission(ids_test, y_submission, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
