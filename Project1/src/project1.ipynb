{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocessing import preprocessing\n",
    "from features_engineering import augment\n",
    "from implementations import *\n",
    "from cross_validation import *\n",
    "from proj1_helpers import *\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "y, tX_train, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a second axis to y for dimension compatitbility reasons\n",
    "y=y[:,np.newaxis]\n",
    "\n",
    "#computing the size of the prediction to generate\n",
    "pred_len=tX_test.shape[0]\n",
    "\n",
    "#all available regression functions\n",
    "lq=lambda a,b,c,d,e,f:least_squares(a,b)\n",
    "lqgd=lambda a,b,c,d,e,f: least_squares_GD(a, b, d, e, f)\n",
    "lqsgd=lambda a,b,c,d,e,f: least_squares_SGD(a, b, d, e, f)\n",
    "r=lambda a,b,c,d,e,f: ridge_regression(a, b, c)\n",
    "lgd=lambda a,b,c,d,e,f: logistic_regression(a,b,d,e,f)\n",
    "lsgd=lambda a,b,c,d,e,f: logistic_regression_SGD(a,b,d,e,f)\n",
    "rlgd=reg_logistic_regression\n",
    "rlsgd=reg_logistic_regression_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(perc,y,x):\n",
    "    \"\"\"computes a (perc, 1-perc) split of x and y\"\"\"\n",
    "    np.random.seed(seed=1)\n",
    "    sample_size=len(y)\n",
    "    cut_ind=int(perc*sample_size)\n",
    "    shuffle_indices = np.random.permutation(sample_size)\n",
    "    shuffled_x=x[shuffle_indices]\n",
    "    shuffled_y=y[shuffle_indices]\n",
    "    return shuffled_y[:cut_ind], shuffled_x[:cut_ind],shuffled_y[cut_ind:], shuffled_x[cut_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_expand(xtr,xte,degrees):\n",
    "    \"\"\"preprocesses and then expands the samples\"\"\"\n",
    "    (xstr, mtr) = preprocessing(xtr)\n",
    "    (xste, mte) = preprocessing(xte)\n",
    "    for it,(degree,xtr,xte) in enumerate(zip(degrees,xstr,xste)):\n",
    "        xstr[it]=augment(xtr,degree)\n",
    "        xste[it]=augment(xte,degree)\n",
    "    return xstr, mtr, xste, mte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(tx,w,logistic):\n",
    "    \"\"\"generates class predictions given weights, and a test data matrix\"\"\"\n",
    "    y_pred= 2*sigmoid(tx.dot(w))-1 if logistic else tx.dot(w)\n",
    "    y_pred[np.where(y_pred <= 0)] = -1\n",
    "    y_pred[np.where(y_pred > 0)] = 1\n",
    "    return y_pred\n",
    "\n",
    "def predictions(ys, tx, px, mask_t, mask_p, reg_fs, len_pred, lambdas, max_iters, gammas, logistics):\n",
    "    \"\"\"generates predictions using the regression function reg_f (trained on y,tx) and the inputs px\"\"\"\n",
    "    y_pred = np.zeros((len_pred,1))\n",
    "    for x_train, mask_train, x_test, mask_test, lambda_, max_iter, gamma, logistic, reg_f, y_i in zip(tx, mask_t, px, mask_p, lambdas, max_iters, gammas, logistics, reg_fs, ys):\n",
    "        #print(\"#######New subset#######\")\n",
    "        y_correspond = y_i[mask_train]\n",
    "        x_train\n",
    "        #print(\"Augmented train\")\n",
    "        initial_w= np.zeros((x_train.shape[1], 1))\n",
    "        w,_ = reg_f(y_correspond, x_train, lambda_, initial_w, max_iter, gamma)\n",
    "        #print(\"Computed weights\")\n",
    "        del x_train\n",
    "        #print(\"Augmented test\")\n",
    "        y_pred[mask_test] = predict_labels(x_test,w,logistic)\n",
    "        del w\n",
    "        #print(\"Computed predictions\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cross(ytr, yte, xstr, mtr, xste, mte, reg_fs, lambdas, max_iters, gammas, logistics):\n",
    "    \"\"\"estimates the true performance of reg_fs through basic cross-validation between \n",
    "    a test and training set of samples\"\"\"\n",
    "    ytr_l=np.where(ytr==-1,0,1)\n",
    "    size_pred=len(yte)\n",
    "    ys=[(ytr_l if l else ytr) for l in logistics]\n",
    "    y_bar=predictions(ys, xstr, xste, mtr, mte, reg_fs, size_pred, lambdas, max_iters, gammas, logistics)\n",
    "    return np.sum((yte==y_bar))/len(yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_kfolds(y_train, x_train, num_folds, mtr, reg_fs, lambdas, max_iters, gammas, logistics):\n",
    "    scores = []\n",
    "    #ytr_l=np.where(y_train==-1,0,1)\n",
    "    #ys=[(ytr_l if l else y_train) for l in logistics]\n",
    "    for x_sub,mask,lambda_, max_iter, gamma, logistic, reg_f in zip(x_train,mtr,lambdas,max_iters,gammas,logistics,reg_fs):\n",
    "        y_correspond = y_train[mask]\n",
    "        scores_sub = []\n",
    "        for x_train_s, x_val_s, y_train_s, y_val_s in k_fold_splits(y_correspond, x_sub, num_folds):\n",
    "            size_pred=len(y_val_s)\n",
    "            y_pred = np.zeros((size_pred,1))\n",
    "            initial_w= np.zeros((x_train_s.shape[1], 1))\n",
    "            w,_ = reg_f(y_train_s, x_train_s, lambda_, initial_w, max_iter, gamma)\n",
    "            y_pred = predict_labels(x_val_s,w,logistic)\n",
    "            score = np.mean(y_pred == y_val_s)\n",
    "            scores_sub.append(score)\n",
    "        print(\"finished subset average is :\",np.array(scores_sub).mean())\n",
    "        scores.append(np.array(scores_sub).mean())\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split percentage for the cross-validation\n",
    "perc=0.8\n",
    "#generating the training and test sets\n",
    "ytr,xtr,yte,xte=split(perc,y,tX_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degrees of expansion for each of the subsets generated by the preprocessing\n",
    "degrees=[3,3,3]\n",
    "\n",
    "#preprocessing and expanding both the training and the test set\n",
    "xstr, mtr, xste, mte=preprocess_and_expand(xtr,xte,degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid searching the best lmbda for ridge regression\n",
    "\n",
    "# setting the search interval\n",
    "interval_size=10\n",
    "interval=np.linspace(-20, 0, interval_size)\n",
    "\n",
    "# models to test\n",
    "test_models=[r]\n",
    "test_logistics=[False]\n",
    "\n",
    "# setting the models\n",
    "logistics=[False,False,False]\n",
    "reg_fs= [r,r,r]\n",
    "datasets=3\n",
    "\n",
    "# setting model parameters\n",
    "max_iters=[100000,100000,100000] \n",
    "gammas=[10**-8,10**-8,10**-8] \n",
    "\n",
    "# initializing model hyperparameters \n",
    "lda1=10**-14\n",
    "lda2=10**-12\n",
    "lda3=10**-16\n",
    "lambdas=[lda1,lda2,lda3]\n",
    "\n",
    "# initializing the results container\n",
    "results=np.zeros((interval_size*len(test_models),3))\n",
    "\n",
    "# finding lambdas\n",
    "for data_num in range(datasets):\n",
    "    for i, m in enumerate(test_models):\n",
    "        for j, v in enumerate(interval):\n",
    "            lda1=10**v  \n",
    "            lambdas[data_num]=lda1\n",
    "            reg_fs[data_num]=m\n",
    "            logistics[data_num]=test_logistics[i]\n",
    "            performance=basic_cross(ytr, yte, xstr, mtr, xste, mte, reg_fs, lambdas, max_iters, gammas, logistics)\n",
    "            results[interval_size*i+j]=[lda1,i,performance]\n",
    "            print(\"Step \",data_num+1,\": \", 100*(i*interval_size+j+1)/(interval_size*len(test_models)), \"% done\")\n",
    "    \n",
    "    print(results[np.where(results[:,2]==np.max(results[:,2]))])\n",
    "    lambdas[data_num]=results[np.where(results[:,2]==np.max(results[:,2]))][0,0]\n",
    "    index_mod=int(results[np.where(results[:,2]==np.max(results[:,2]))][0,1])\n",
    "    reg_fs[data_num]=test_models[index_mod]\n",
    "    logistics[data_num]= test_logistics[index_mod]\n",
    "    results=np.zeros((interval_size*len(test_models),3))\n",
    "\n",
    "# estimating the performance of the best overall model\n",
    "performance=basic_cross(ytr, yte, xstr, mtr, xste, mte, reg_fs, lambdas, max_iters, gammas, logistics)\n",
    "print(\"Best performance: \",performance*100, \"%\") \n",
    "print(\"Best lambdas: \", lambdas)\n",
    "print(\"Best models: \", [(\"r\" if m==r else \"lsgd\") for m in reg_fs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for degree 2\n",
    "lda1=1.2*10**-15\n",
    "lda2=1.2*10**-10\n",
    "lda3=1.2*10**-14\n",
    "reg_fs=[r,r,r]\n",
    "logistics=[False,False,False]\n",
    "lambdas=[lda1,lda2,lda3]\n",
    "lambdas=[lda1,lda2,lda3]\n",
    "gamma,max_iters= [0,0,0],[0,0,0]\n",
    "\n",
    "performance=basic_cross(ytr, yte, xstr, mtr, xste, mte, reg_fs, lambdas, max_iters, gammas, logistics)\n",
    "print(\"The best performance for the degree 2 espansion is: \", performance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for degree 3\n",
    "reg_fs=[r,r,r]\n",
    "logistics=[False,False,False]\n",
    "lambdas=[3.5938136638046256e-05, 3.5938136638046256e-05, 0.005994842503189421]\n",
    "gamma,max_iters= [0,0,0],[0,0,0]\n",
    "\n",
    "performance=basic_cross(ytr, yte, xstr, mtr, xste, mte, reg_fs, lambdas, max_iters, gammas, logistics)\n",
    "print(\"The best performance for the degree 3 espansion is: \", performance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanding for k cross-validation\n",
    "degrees=[3,3,3]\n",
    "def preprocess_and_expandkcross(xtr,degrees):\n",
    "    \"\"\"preprocesses and then expands the samples\"\"\"\n",
    "    (xstr, mtr) = preprocessing(xtr)\n",
    "    for it,(degree,xtr) in enumerate(zip(degrees,xstr)):\n",
    "        xstr[it]=augment(xtr,degree)\n",
    "    return xstr, mtr\n",
    "\n",
    "#preprocessing and expanding both the training and the test set\n",
    "xtraink, mtr=preprocess_and_expandkcross(tX_train,degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for degree 3\n",
    "lda1=2.26*10**-15\n",
    "lda2=2.42*10**-12\n",
    "lda3=2.21*10**-16\n",
    "reg_fs=[r,r,r]\n",
    "logistics=[False,False,False]\n",
    "lambdas=[lda1,lda2,lda3]\n",
    "gammas,max_iters= [0,0,0],[0,0,0]\n",
    "\n",
    "performance=cross_validation_kfolds(y, xtraink, 5, mtr, reg_fs, lambdas, max_iters, gammas, logistics)\n",
    "print(\"The best performance for the degree 3 espansion is: \", performance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 2\n",
      "Degree 3\n",
      "Degree 2\n",
      "Degree 3\n",
      "Degree 2\n",
      "Degree 3\n",
      "Degree 2\n",
      "Degree 3\n",
      "Degree 2\n",
      "Degree 3\n",
      "Degree 2\n",
      "Degree 3\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-378f98f6cde7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mxstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxste\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmte\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess_and_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msize_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myte\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-837139bb0230>\u001b[0m in \u001b[0;36mpreprocess_and_expand\u001b[1;34m(xtr, xte, degrees)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxte\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mxstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mxste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxte\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mxstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxste\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmte\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\School\\Machine Learning\\Projects\\Project1\\src\\features_engineering.py\u001b[0m in \u001b[0;36maugment\u001b[1;34m(x, total_degree, simple_degree, tan_hyp_deg, ilog_deg, root_deg)\u001b[0m\n\u001b[0;32m     41\u001b[0m             x_aug = np.append(x_aug,\n\u001b[0;32m     42\u001b[0m                               np.prod(x3d[0, :, unique_combinations],\n\u001b[1;32m---> 43\u001b[1;33m                                       axis=1).T,\n\u001b[0m\u001b[0;32m     44\u001b[0m                               axis=1)\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2583\u001b[0m     \"\"\"\n\u001b[0;32m   2584\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2585\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for degree 3\n",
    "reg_fs=[r,r,r]\n",
    "logistics=[False,False,False]\n",
    "lda1=2.26*10**-15\n",
    "lda2=2.42*10**-12\n",
    "lda3=2.21*10**-16\n",
    "lambdas=[lda1,lda2,lda3]\n",
    "gamma,max_iters= [0,0,0],[0,0,0]\n",
    "degrees=[3,3,3]\n",
    "xstr, mtr, xste, mte=preprocess_and_expand(tX_train,tX_test,degrees)\n",
    "size_pred=len(yte)\n",
    "ys=[y,y,y]\n",
    "y_bar=predictions(ys, xstr, xste, mtr, mte, reg_fs, size_pred, lambdas, max_iters, gammas, logistics)\n",
    "create_csv_submission(ids_test, y_bar, \"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
