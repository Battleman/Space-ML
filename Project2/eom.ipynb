{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV\n",
    "#importing the models\n",
    "import Kmeans\n",
    "import ALS\n",
    "import NN\n",
    "import Surprize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_vote(predictions):\n",
    "    #computing the median\n",
    "    median=np.median(predictions,axis=0)\n",
    "    #making sure the result is an int (not the case if the amount of predictions is even)\n",
    "    bounded_median=np.floor(median)\n",
    "    return bounded_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_vote(predictions):\n",
    "    #computing the mode\n",
    "    return stats.mode(predictions,axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maj_vote(predictions):\n",
    "    top=predictions.iloc[0][:,np.newaxis]\n",
    "    mode=stats.mode(predictions,axis=0)\n",
    "    freq=mode[1].T/predictions.shape[0]\n",
    "    return np.where(freq<0.5,top,mode[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_vote(predictions):\n",
    "    return np.round(np.mean(predictions,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(voting_f):\n",
    "    #useful constants\n",
    "    submission_path='submission.csv'\n",
    "    training_path = \"data/data_train.csv\"\n",
    "    format_path = \"data/sampleSubmission.csv\"\n",
    "    #Loading the data\n",
    "    print(\"Loading datasets\")\n",
    "    try:\n",
    "        input_ = pd.read_csv(training_path)\n",
    "        format_ = pd.read_csv(format_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Impossible to load training or format files, \"\n",
    "              \"please double check\")\n",
    "        return pd.DataFrame([])\n",
    "    #computing the prediction of the ALS algorithm\n",
    "    predictions=ALS.main(input_.copy(), format_.copy())\n",
    "    print(predictions.head(),format_.head())\n",
    "    #computing multiple predictions of the kmeans algorithm\n",
    "    for k in [6]:\n",
    "        predictions=predictions.merge(Kmeans.main(input_.copy(), format_.copy(), k),on='Id')\n",
    "        print(predictions.shape)\n",
    "    #computing the prediction of the NN algorithm\n",
    "    predictions=predictions.merge(NN.main(input_.copy(), format_.copy()),on='Id')\n",
    "    print(predictions.shape)\n",
    "    #setting 'Id' as the index of the aggregation of predictions\n",
    "    predictions.set_index('Id', inplace=True)\n",
    "    #finding the best prediction through the voting function\n",
    "    print('Voting...')\n",
    "    predictions['Prediction']=voting_f(predictions.T)\n",
    "    #exporting the final prediction using the submission path\n",
    "    print('Exporting the final prediction...')\n",
    "    predictions[['Prediction']].to_csv(submission_path)\n",
    "    print('Done!')\n",
    "    return predictions[['Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco=vote(cluster_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find predictors weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful constants\n",
    "submission_path='submission.csv'\n",
    "training_path = \"data/data_train.csv\"\n",
    "format_path = \"data/sampleSubmission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "print(\"Loading datasets\")\n",
    "try:\n",
    "    input_ = pd.read_csv(training_path)\n",
    "    format_ = pd.read_csv(format_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"Impossible to load training or format files, \"\n",
    "          \"please double check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "np.random.seed(1)\n",
    "train, test =sklearn.model_selection.train_test_split(input_,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#computing the predictions of the Surprize algorithm\n",
    "predictions_surprize_test = Surprize.main(train.copy(), test.copy(), \n",
    "                                          cache_name=\"test\", force_recompute=[\"SVD\", \"NMF\"])\n",
    "\n",
    "# #computing the predictions of the ALS algorithm\n",
    "# predictions_als_test=ALS.main(train.copy(), test.copy())\n",
    "\n",
    "# #computing the best prediction of the kmeans algorithm\n",
    "# k=6\n",
    "# predictions_kmeans_test = Kmeans.main(train.copy(), test.copy(), k, rounded=False)\n",
    "\n",
    "# #computing the prediction of the NN algorithm\n",
    "# predictions_nn_test = NN.main(train.copy(), test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ratings_test = test.copy()\n",
    "true_ratings_test.set_index(\"Id\", inplace=True)\n",
    "true_ratings_test.columns = [\"y\"]\n",
    "concat_test = pd.concat([predictions_als_test, \n",
    "                    predictions_kmeans_test, \n",
    "                    predictions_nn_test, \n",
    "                    predictions_surprize_test, \n",
    "                    true_ratings_test], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_train, preds_test = train_test_split(concat)\n",
    "X = concat_test.loc[:,~(concat_test.columns == \"y\")]\n",
    "y = concat_test.loc[:, \"y\"]\n",
    "rr = RidgeCV(alphas=np.linspace(1e-5, 5, 3000), store_cv_values=True).fit(X,y)\n",
    "predictor_coefficients = dict(zip(X.columns, rr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1e-5, 5, 3000), rr.cv_values_.mean(axis=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_surprize_final = Surprize.main(input_.copy(), format_.copy(), \n",
    "                                           cache_name=\"final\", force_recompute=[\"SVD\", \"NMF\"])\n",
    "predictions_als_final=ALS.main(input_.copy(), format_.copy(), cache_name=\"final\")\n",
    "\n",
    "#computing the best prediction of the kmeans algorithm\n",
    "k=6\n",
    "predictions_kmeans_final = Kmeans.main(input_.copy(), format_.copy(), k, rounded=False)\n",
    "predictions_nn_final = NN.main(input_.copy(), format_.copy())\n",
    "concat_final = pd.concat([predictions_als_final, \n",
    "                    predictions_kmeans_final, \n",
    "                    predictions_nn_final, \n",
    "                    predictions_surprize_final], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_final[\"Prediction\"] = rr.intercept_\n",
    "for col in concat_final:\n",
    "    if col != \"Prediction\":\n",
    "        concat_final[\"Prediction\"] += concat_final.loc[:, col]*predictor_coefficients[col]\n",
    "concat_final[\"Prediction\"] = concat_final[\"Prediction\"].apply(lambda x: int(np.clip(np.round(x),1,5)))\n",
    "concat_final.index.name = \"Id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_final.to_csv(submission_path, columns=[\"Prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
