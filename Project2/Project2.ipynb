{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from proj2_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r44_c1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r61_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r67_c1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r72_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r86_c1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Prediction\n",
       "0  r44_c1           4\n",
       "1  r61_c1           3\n",
       "2  r67_c1           4\n",
       "3  r72_c1           3\n",
       "4  r86_c1           5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the training data\n",
    "data=pd.read_csv('data_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[44, 1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[61, 1]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[67, 1]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[72, 1]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[86, 1]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Prediction\n",
       "0  [44, 1]           4\n",
       "1  [61, 1]           3\n",
       "2  [67, 1]           4\n",
       "3  [72, 1]           3\n",
       "4  [86, 1]           5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting row and column numbers\n",
    "data['Id']=data['Id'].apply(lambda x: re.findall(r'\\d+', str(x)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Row</th>\n",
       "      <th>Col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction Row Col\n",
       "0           4  44   1\n",
       "1           3  61   1\n",
       "2           4  67   1\n",
       "3           3  72   1\n",
       "4           5  86   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Row and column values to features\n",
    "num_id_data=data\n",
    "num_id_data[['Row', 'Col']]=pd.DataFrame(data.Id.values.tolist(), index= data.index)\n",
    "num_id_data=num_id_data.drop(columns='Id')\n",
    "num_id_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Col</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Col     1   10  100  1000  101  102  103  104  105  106 ...   990  991  992  \\\n",
       "Row                                                     ...                   \n",
       "1     NaN  5.0  NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "10    NaN  NaN  NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "100   NaN  5.0  NaN   NaN  5.0  NaN  3.0  2.0  2.0  NaN ...   NaN  NaN  NaN   \n",
       "1000  NaN  2.0  4.0   2.0  5.0  NaN  NaN  NaN  4.0  NaN ...   NaN  NaN  4.0   \n",
       "10000 NaN  4.0  NaN   3.0  NaN  NaN  NaN  NaN  NaN  3.0 ...   NaN  2.0  NaN   \n",
       "\n",
       "Col    993  994  995  996  997  998  999  \n",
       "Row                                       \n",
       "1      NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "10     NaN  NaN  5.0  NaN  4.0  NaN  NaN  \n",
       "100    NaN  NaN  1.0  NaN  NaN  NaN  NaN  \n",
       "1000   2.0  NaN  5.0  1.0  NaN  2.0  3.0  \n",
       "10000  NaN  NaN  NaN  3.0  3.0  NaN  NaN  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cli_vs_mov=num_id_data.pivot(index='Row', columns='Col', values='Prediction')\n",
    "cli_vs_mov.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_clusters(data, k):\n",
    "    \"\"\"initialize the k cluster centers (the means).\n",
    "    input:\n",
    "        data: original data with shape (num_sample, num_feature).\n",
    "        k: predefined number of clusters for the k-means algorithm.\n",
    "    output:\n",
    "        a numpy array with shape (k, num_feature)\n",
    "    \"\"\"\n",
    "    # ***************************************************************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: initialize cluster centers.\n",
    "    # TODO: Make sure you choose k clusters from the data itself,\n",
    "    #       or ensure otherwise that your initializations have the same scaling as the data\n",
    "    # ***************************************************************************************************\n",
    "    random=np.random.rand(k,data.shape[1])\n",
    "    min_data=np.nanmin(data,axis=0)\n",
    "    max_data=np.nanmax(data,axis=0)\n",
    "    return np.random.uniform(min_data,max_data,(k,data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_distance_matrix(data, mu):\n",
    "    \"\"\"build a distance matrix.\n",
    "    return\n",
    "        distance matrix:\n",
    "            row of the matrix represents the data point,\n",
    "            column of the matrix represents the k-th cluster.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: build distance matrix\n",
    "    # ***************************************************\n",
    "    return np.array([np.nansum((data-mu[i])**2,axis=1) for i in range(len(mu))]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_kmeans_parameters(data, mu_old):\n",
    "    \"\"\"update the parameter of kmeans\n",
    "    return:\n",
    "        losses: loss of each data point with shape (num_samples, 1)\n",
    "        assignments: assignments vector z with shape (num_samples, 1)\n",
    "        mu: mean vector mu with shape (k, num_features)\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: update kmeans parameters\n",
    "    # ***************************************************\n",
    "    d=build_distance_matrix(data, mu_old)\n",
    "    losses=np.min(d,1)\n",
    "    assignments=np.argmin(d,1)\n",
    "    mu=np.array([np.mean(data[assignments==i],0) for i in range(mu_old.shape[0])])\n",
    "    mu=np.where(np.isnan(mu),mu_old,mu)\n",
    "    return losses,assignments,mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, k, max_iters, threshold):\n",
    "    \"\"\"run the k-means algorithm.\"\"\"\n",
    "    output_figure = \"kmeans_figures/\"\n",
    "    #Initialize the cluster.\n",
    "    mu_old = initialize_clusters(data, k)\n",
    "    average_loss=0\n",
    "    #Start the kmeans algorithm.\n",
    "    for iter in range(max_iters):\n",
    "        #Update z and mu\n",
    "        losses, assignments, mu = update_kmeans_parameters(data, mu_old)\n",
    "        #Calculate the average loss over all points\n",
    "        old_avg_loss=average_loss\n",
    "        average_loss = np.mean(losses)\n",
    "        print(\"The current iteration of k-means is: {i}, \\\n",
    "               the average loss is {l}.\".format(i=iter, l=average_loss))\n",
    "        #Check converge\n",
    "        if iter > 0 and np.abs(average_loss - old_avg_loss) < threshold:\n",
    "            break\n",
    "        #Output plot\n",
    "        #Plot(data, mu, mu_old, output_figure + \"kmean_iter{i}\".format(i=iter))\n",
    "        #Update k-means information.\n",
    "        mu_old = mu\n",
    "    return assignments, mu, average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the most common value for each column of n\n",
    "def most_common(x):\n",
    "    top_freq=[]\n",
    "    for i in range(x.shape[1]):\n",
    "        temp=np.unique(x.iloc[:,i],return_counts=True)\n",
    "        top_freq=np.append(top_freq,temp[0][temp[1].argmax()])\n",
    "    return top_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1 :\n",
      "The current iteration of k-means is: 0,                the average loss is 385.7680641185425.\n",
      "The current iteration of k-means is: 1,                the average loss is 124.72241850996271.\n",
      "The current iteration of k-means is: 2,                the average loss is 124.72241850996271.\n",
      "For k= 2 :\n",
      "The current iteration of k-means is: 0,                the average loss is 379.3810192390307.\n",
      "The current iteration of k-means is: 1,                the average loss is 123.15840740377902.\n",
      "The current iteration of k-means is: 2,                the average loss is 119.49095519942665.\n",
      "The current iteration of k-means is: 3,                the average loss is 118.85519868493108.\n",
      "The current iteration of k-means is: 4,                the average loss is 118.80975286317283.\n",
      "The current iteration of k-means is: 5,                the average loss is 118.8039094488833.\n",
      "The current iteration of k-means is: 6,                the average loss is 118.80279017278994.\n",
      "The current iteration of k-means is: 7,                the average loss is 118.80246497073027.\n",
      "For k= 3 :\n",
      "The current iteration of k-means is: 0,                the average loss is 359.9115301504418.\n",
      "The current iteration of k-means is: 1,                the average loss is 123.23425151510509.\n",
      "The current iteration of k-means is: 2,                the average loss is 121.29150995655782.\n",
      "The current iteration of k-means is: 3,                the average loss is 118.18507209377005.\n",
      "The current iteration of k-means is: 4,                the average loss is 117.46840405016046.\n",
      "The current iteration of k-means is: 5,                the average loss is 117.32489256842281.\n",
      "The current iteration of k-means is: 6,                the average loss is 117.26727008662638.\n",
      "The current iteration of k-means is: 7,                the average loss is 117.23490751526184.\n",
      "The current iteration of k-means is: 8,                the average loss is 117.20479805550117.\n",
      "The current iteration of k-means is: 9,                the average loss is 117.1786568723728.\n",
      "The current iteration of k-means is: 10,                the average loss is 117.15546924189168.\n",
      "The current iteration of k-means is: 11,                the average loss is 117.13229951027546.\n",
      "The current iteration of k-means is: 12,                the average loss is 117.11215968934042.\n",
      "The current iteration of k-means is: 13,                the average loss is 117.09788259763616.\n",
      "The current iteration of k-means is: 14,                the average loss is 117.08487273148224.\n",
      "The current iteration of k-means is: 15,                the average loss is 117.07089183441684.\n",
      "The current iteration of k-means is: 16,                the average loss is 117.06130352035456.\n",
      "The current iteration of k-means is: 17,                the average loss is 117.05347746629307.\n",
      "The current iteration of k-means is: 18,                the average loss is 117.04489258266408.\n",
      "The current iteration of k-means is: 19,                the average loss is 117.03810905010009.\n",
      "The current iteration of k-means is: 20,                the average loss is 117.0328469452943.\n",
      "The current iteration of k-means is: 21,                the average loss is 117.02736392063268.\n",
      "The current iteration of k-means is: 22,                the average loss is 117.02137217639336.\n",
      "The current iteration of k-means is: 23,                the average loss is 117.01569298337319.\n",
      "The current iteration of k-means is: 24,                the average loss is 117.01143331670404.\n",
      "The current iteration of k-means is: 25,                the average loss is 117.00837795733631.\n",
      "The current iteration of k-means is: 26,                the average loss is 117.00534664226565.\n",
      "The current iteration of k-means is: 27,                the average loss is 117.00283508112153.\n",
      "The current iteration of k-means is: 28,                the average loss is 117.00052559334003.\n",
      "The current iteration of k-means is: 29,                the average loss is 116.99779993776612.\n",
      "The current iteration of k-means is: 30,                the average loss is 116.99589830765827.\n",
      "The current iteration of k-means is: 31,                the average loss is 116.99439001189748.\n",
      "The current iteration of k-means is: 32,                the average loss is 116.99226893864963.\n",
      "The current iteration of k-means is: 33,                the average loss is 116.9903034491353.\n",
      "The current iteration of k-means is: 34,                the average loss is 116.98718357843096.\n",
      "The current iteration of k-means is: 35,                the average loss is 116.98371876846622.\n",
      "The current iteration of k-means is: 36,                the average loss is 116.98131729059823.\n",
      "The current iteration of k-means is: 37,                the average loss is 116.9800057924347.\n",
      "The current iteration of k-means is: 38,                the average loss is 116.97857099483954.\n",
      "The current iteration of k-means is: 39,                the average loss is 116.97710768359939.\n",
      "The current iteration of k-means is: 40,                the average loss is 116.97572836396817.\n",
      "The current iteration of k-means is: 41,                the average loss is 116.97402285336061.\n",
      "The current iteration of k-means is: 42,                the average loss is 116.97264464433943.\n",
      "The current iteration of k-means is: 43,                the average loss is 116.972209472333.\n",
      "For k= 4 :\n",
      "The current iteration of k-means is: 0,                the average loss is 337.13046634695377.\n",
      "The current iteration of k-means is: 1,                the average loss is 121.41207830462055.\n",
      "The current iteration of k-means is: 2,                the average loss is 117.53897337903727.\n",
      "The current iteration of k-means is: 3,                the average loss is 116.66929294920051.\n",
      "The current iteration of k-means is: 4,                the average loss is 116.31168615603538.\n",
      "The current iteration of k-means is: 5,                the average loss is 116.07404222807143.\n",
      "The current iteration of k-means is: 6,                the average loss is 115.87340369645469.\n",
      "The current iteration of k-means is: 7,                the average loss is 115.7156151331941.\n",
      "The current iteration of k-means is: 8,                the average loss is 115.6133649827244.\n",
      "The current iteration of k-means is: 9,                the average loss is 115.54662156608245.\n",
      "The current iteration of k-means is: 10,                the average loss is 115.5044231945252.\n",
      "The current iteration of k-means is: 11,                the average loss is 115.47779227443358.\n",
      "The current iteration of k-means is: 12,                the average loss is 115.46326156594982.\n",
      "The current iteration of k-means is: 13,                the average loss is 115.45536715509117.\n",
      "The current iteration of k-means is: 14,                the average loss is 115.44824580165474.\n",
      "The current iteration of k-means is: 15,                the average loss is 115.44503029204542.\n",
      "The current iteration of k-means is: 16,                the average loss is 115.44297352857865.\n",
      "The current iteration of k-means is: 17,                the average loss is 115.44140500142174.\n",
      "The current iteration of k-means is: 18,                the average loss is 115.43996388288228.\n",
      "The current iteration of k-means is: 19,                the average loss is 115.43906914093247.\n",
      "For k= 5 :\n",
      "The current iteration of k-means is: 0,                the average loss is 356.64442297706063.\n",
      "The current iteration of k-means is: 1,                the average loss is 121.71381916680173.\n",
      "The current iteration of k-means is: 2,                the average loss is 117.23960988143601.\n",
      "The current iteration of k-means is: 3,                the average loss is 115.94845691950505.\n",
      "The current iteration of k-means is: 4,                the average loss is 115.40270696300794.\n",
      "The current iteration of k-means is: 5,                the average loss is 115.05041670786812.\n",
      "The current iteration of k-means is: 6,                the average loss is 114.8324952207907.\n",
      "The current iteration of k-means is: 7,                the average loss is 114.71021127353912.\n",
      "The current iteration of k-means is: 8,                the average loss is 114.64304313765078.\n",
      "The current iteration of k-means is: 9,                the average loss is 114.60518695459324.\n",
      "The current iteration of k-means is: 10,                the average loss is 114.57379076862402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 11,                the average loss is 114.55184203876607.\n",
      "The current iteration of k-means is: 12,                the average loss is 114.53573644240517.\n",
      "The current iteration of k-means is: 13,                the average loss is 114.52195394183502.\n",
      "The current iteration of k-means is: 14,                the average loss is 114.51113683058378.\n",
      "The current iteration of k-means is: 15,                the average loss is 114.50413031105506.\n",
      "The current iteration of k-means is: 16,                the average loss is 114.50034585643111.\n",
      "The current iteration of k-means is: 17,                the average loss is 114.4962245893175.\n",
      "The current iteration of k-means is: 18,                the average loss is 114.49214867158162.\n",
      "The current iteration of k-means is: 19,                the average loss is 114.48934524411554.\n",
      "The current iteration of k-means is: 20,                the average loss is 114.48709385638828.\n",
      "The current iteration of k-means is: 21,                the average loss is 114.48522088406074.\n",
      "The current iteration of k-means is: 22,                the average loss is 114.48304235782763.\n",
      "The current iteration of k-means is: 23,                the average loss is 114.48196081497092.\n",
      "The current iteration of k-means is: 24,                the average loss is 114.48077673333064.\n",
      "The current iteration of k-means is: 25,                the average loss is 114.47872323878494.\n",
      "The current iteration of k-means is: 26,                the average loss is 114.47705858413852.\n",
      "The current iteration of k-means is: 27,                the average loss is 114.47524647622085.\n",
      "The current iteration of k-means is: 28,                the average loss is 114.4741265810273.\n",
      "The current iteration of k-means is: 29,                the average loss is 114.47372903950631.\n",
      "For k= 6 :\n",
      "The current iteration of k-means is: 0,                the average loss is 335.13753694722453.\n",
      "The current iteration of k-means is: 1,                the average loss is 120.86541027378533.\n",
      "The current iteration of k-means is: 2,                the average loss is 116.42215622558263.\n",
      "The current iteration of k-means is: 3,                the average loss is 115.30030035997105.\n",
      "The current iteration of k-means is: 4,                the average loss is 114.81036529525828.\n",
      "The current iteration of k-means is: 5,                the average loss is 114.50927039523565.\n",
      "The current iteration of k-means is: 6,                the average loss is 114.32848308655724.\n",
      "The current iteration of k-means is: 7,                the average loss is 114.19581568153662.\n",
      "The current iteration of k-means is: 8,                the average loss is 114.10979251373138.\n",
      "The current iteration of k-means is: 9,                the average loss is 114.0529518031683.\n",
      "The current iteration of k-means is: 10,                the average loss is 114.01352667786698.\n",
      "The current iteration of k-means is: 11,                the average loss is 113.98677964331183.\n",
      "The current iteration of k-means is: 12,                the average loss is 113.9683422338.\n",
      "The current iteration of k-means is: 13,                the average loss is 113.95079596051379.\n",
      "The current iteration of k-means is: 14,                the average loss is 113.93732987116306.\n",
      "The current iteration of k-means is: 15,                the average loss is 113.92867827967709.\n",
      "The current iteration of k-means is: 16,                the average loss is 113.91906566367322.\n",
      "The current iteration of k-means is: 17,                the average loss is 113.9122418454889.\n",
      "The current iteration of k-means is: 18,                the average loss is 113.90607710326012.\n",
      "The current iteration of k-means is: 19,                the average loss is 113.90040829885216.\n",
      "The current iteration of k-means is: 20,                the average loss is 113.89202541881109.\n",
      "The current iteration of k-means is: 21,                the average loss is 113.88499128041214.\n",
      "The current iteration of k-means is: 22,                the average loss is 113.87885714489694.\n",
      "The current iteration of k-means is: 23,                the average loss is 113.87302709323731.\n",
      "The current iteration of k-means is: 24,                the average loss is 113.86914782517324.\n",
      "The current iteration of k-means is: 25,                the average loss is 113.86614287461107.\n",
      "The current iteration of k-means is: 26,                the average loss is 113.86313424673173.\n",
      "The current iteration of k-means is: 27,                the average loss is 113.86063869694601.\n",
      "The current iteration of k-means is: 28,                the average loss is 113.85937261096105.\n",
      "The current iteration of k-means is: 29,                the average loss is 113.8579162175578.\n",
      "The current iteration of k-means is: 30,                the average loss is 113.85605352381393.\n",
      "The current iteration of k-means is: 31,                the average loss is 113.85469358624923.\n",
      "The current iteration of k-means is: 32,                the average loss is 113.85281043315435.\n",
      "The current iteration of k-means is: 33,                the average loss is 113.85175408063128.\n",
      "The current iteration of k-means is: 34,                the average loss is 113.85134016536148.\n",
      "For k= 7 :\n",
      "The current iteration of k-means is: 0,                the average loss is 335.8556385210341.\n",
      "The current iteration of k-means is: 1,                the average loss is 120.18581246417153.\n",
      "The current iteration of k-means is: 2,                the average loss is 115.93663029406385.\n",
      "The current iteration of k-means is: 3,                the average loss is 114.79772164434176.\n",
      "The current iteration of k-means is: 4,                the average loss is 114.19543472175451.\n",
      "The current iteration of k-means is: 5,                the average loss is 113.83915409796215.\n",
      "The current iteration of k-means is: 6,                the average loss is 113.60325513936202.\n",
      "The current iteration of k-means is: 7,                the average loss is 113.44243701507583.\n",
      "The current iteration of k-means is: 8,                the average loss is 113.3300745849325.\n",
      "The current iteration of k-means is: 9,                the average loss is 113.25590203310091.\n",
      "The current iteration of k-means is: 10,                the average loss is 113.20465304199611.\n",
      "The current iteration of k-means is: 11,                the average loss is 113.1698101410595.\n",
      "The current iteration of k-means is: 12,                the average loss is 113.14910887806886.\n",
      "The current iteration of k-means is: 13,                the average loss is 113.13241371844751.\n",
      "The current iteration of k-means is: 14,                the average loss is 113.1188676654472.\n",
      "The current iteration of k-means is: 15,                the average loss is 113.11022767213942.\n",
      "The current iteration of k-means is: 16,                the average loss is 113.10228092352264.\n",
      "The current iteration of k-means is: 17,                the average loss is 113.09764819708776.\n",
      "The current iteration of k-means is: 18,                the average loss is 113.09473628772895.\n",
      "The current iteration of k-means is: 19,                the average loss is 113.09233643895688.\n",
      "The current iteration of k-means is: 20,                the average loss is 113.08983751134203.\n",
      "The current iteration of k-means is: 21,                the average loss is 113.08807485698226.\n",
      "The current iteration of k-means is: 22,                the average loss is 113.08587949598932.\n",
      "The current iteration of k-means is: 23,                the average loss is 113.08480228474876.\n",
      "The current iteration of k-means is: 24,                the average loss is 113.08397834625407.\n",
      "For k= 8 :\n",
      "The current iteration of k-means is: 0,                the average loss is 341.0372633934845.\n",
      "The current iteration of k-means is: 1,                the average loss is 120.22492967176113.\n",
      "The current iteration of k-means is: 2,                the average loss is 115.67054947538213.\n",
      "The current iteration of k-means is: 3,                the average loss is 114.37329350177474.\n",
      "The current iteration of k-means is: 4,                the average loss is 113.71483609970174.\n",
      "The current iteration of k-means is: 5,                the average loss is 113.3663311768987.\n",
      "The current iteration of k-means is: 6,                the average loss is 113.18897632273327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 7,                the average loss is 113.06216243035533.\n",
      "The current iteration of k-means is: 8,                the average loss is 112.9763805951931.\n",
      "The current iteration of k-means is: 9,                the average loss is 112.92306175543463.\n",
      "The current iteration of k-means is: 10,                the average loss is 112.88166431884375.\n",
      "The current iteration of k-means is: 11,                the average loss is 112.85467420325035.\n",
      "The current iteration of k-means is: 12,                the average loss is 112.83587807142679.\n",
      "The current iteration of k-means is: 13,                the average loss is 112.81862440134412.\n",
      "The current iteration of k-means is: 14,                the average loss is 112.80533443116308.\n",
      "The current iteration of k-means is: 15,                the average loss is 112.79064704654441.\n",
      "The current iteration of k-means is: 16,                the average loss is 112.77637430447945.\n",
      "The current iteration of k-means is: 17,                the average loss is 112.76547268767499.\n",
      "The current iteration of k-means is: 18,                the average loss is 112.75920490572899.\n",
      "The current iteration of k-means is: 19,                the average loss is 112.75391538401031.\n",
      "The current iteration of k-means is: 20,                the average loss is 112.74908007853371.\n",
      "The current iteration of k-means is: 21,                the average loss is 112.74613923126161.\n",
      "The current iteration of k-means is: 22,                the average loss is 112.74271230859915.\n",
      "The current iteration of k-means is: 23,                the average loss is 112.7407449800459.\n",
      "The current iteration of k-means is: 24,                the average loss is 112.73836235197342.\n",
      "The current iteration of k-means is: 25,                the average loss is 112.73719999948926.\n",
      "The current iteration of k-means is: 26,                the average loss is 112.73598408711743.\n",
      "The current iteration of k-means is: 27,                the average loss is 112.73481331160117.\n",
      "The current iteration of k-means is: 28,                the average loss is 112.73402539714631.\n",
      "For k= 9 :\n",
      "The current iteration of k-means is: 0,                the average loss is 334.60768324652173.\n",
      "The current iteration of k-means is: 1,                the average loss is 120.49013698423072.\n",
      "The current iteration of k-means is: 2,                the average loss is 115.70777710489912.\n",
      "The current iteration of k-means is: 3,                the average loss is 113.94809966533902.\n",
      "The current iteration of k-means is: 4,                the average loss is 113.31994611933052.\n",
      "The current iteration of k-means is: 5,                the average loss is 113.03678883630121.\n",
      "The current iteration of k-means is: 6,                the average loss is 112.87109539148142.\n",
      "The current iteration of k-means is: 7,                the average loss is 112.7738261494264.\n",
      "The current iteration of k-means is: 8,                the average loss is 112.70017182160167.\n",
      "The current iteration of k-means is: 9,                the average loss is 112.65296372259328.\n",
      "The current iteration of k-means is: 10,                the average loss is 112.62059899876137.\n",
      "The current iteration of k-means is: 11,                the average loss is 112.59358119139881.\n",
      "The current iteration of k-means is: 12,                the average loss is 112.57247620007922.\n",
      "The current iteration of k-means is: 13,                the average loss is 112.5555520138264.\n",
      "The current iteration of k-means is: 14,                the average loss is 112.54368992946002.\n",
      "The current iteration of k-means is: 15,                the average loss is 112.53316857651164.\n",
      "The current iteration of k-means is: 16,                the average loss is 112.52649352855734.\n",
      "The current iteration of k-means is: 17,                the average loss is 112.51989861420005.\n",
      "The current iteration of k-means is: 18,                the average loss is 112.51297103482928.\n",
      "The current iteration of k-means is: 19,                the average loss is 112.50835045185033.\n",
      "The current iteration of k-means is: 20,                the average loss is 112.50390030110837.\n",
      "The current iteration of k-means is: 21,                the average loss is 112.49944853293476.\n",
      "The current iteration of k-means is: 22,                the average loss is 112.49490086290535.\n",
      "The current iteration of k-means is: 23,                the average loss is 112.49277532962952.\n",
      "The current iteration of k-means is: 24,                the average loss is 112.49181619482138.\n",
      "For k= 10 :\n",
      "The current iteration of k-means is: 0,                the average loss is 337.42045123629043.\n",
      "The current iteration of k-means is: 1,                the average loss is 119.7296112982071.\n",
      "The current iteration of k-means is: 2,                the average loss is 115.00429179226947.\n",
      "The current iteration of k-means is: 3,                the average loss is 113.49497148474146.\n",
      "The current iteration of k-means is: 4,                the average loss is 112.88310734244652.\n",
      "The current iteration of k-means is: 5,                the average loss is 112.55216132832639.\n",
      "The current iteration of k-means is: 6,                the average loss is 112.35518032061042.\n",
      "The current iteration of k-means is: 7,                the average loss is 112.2234920532527.\n",
      "The current iteration of k-means is: 8,                the average loss is 112.13311556622419.\n",
      "The current iteration of k-means is: 9,                the average loss is 112.07072717808452.\n",
      "The current iteration of k-means is: 10,                the average loss is 112.02506270605674.\n",
      "The current iteration of k-means is: 11,                the average loss is 111.98994749666085.\n",
      "The current iteration of k-means is: 12,                the average loss is 111.95711710008415.\n",
      "The current iteration of k-means is: 13,                the average loss is 111.92592161518321.\n",
      "The current iteration of k-means is: 14,                the average loss is 111.90121067848035.\n",
      "The current iteration of k-means is: 15,                the average loss is 111.88720025090461.\n",
      "The current iteration of k-means is: 16,                the average loss is 111.87660810577492.\n",
      "The current iteration of k-means is: 17,                the average loss is 111.86575323884611.\n",
      "The current iteration of k-means is: 18,                the average loss is 111.85499890294557.\n",
      "The current iteration of k-means is: 19,                the average loss is 111.84343125328843.\n",
      "The current iteration of k-means is: 20,                the average loss is 111.83411170898611.\n",
      "The current iteration of k-means is: 21,                the average loss is 111.82741916835771.\n",
      "The current iteration of k-means is: 22,                the average loss is 111.82346661366422.\n",
      "The current iteration of k-means is: 23,                the average loss is 111.81964717886527.\n",
      "The current iteration of k-means is: 24,                the average loss is 111.81518861069479.\n",
      "The current iteration of k-means is: 25,                the average loss is 111.81230135591312.\n",
      "The current iteration of k-means is: 26,                the average loss is 111.80936886097426.\n",
      "The current iteration of k-means is: 27,                the average loss is 111.80738806232303.\n",
      "The current iteration of k-means is: 28,                the average loss is 111.8057837064879.\n",
      "The current iteration of k-means is: 29,                the average loss is 111.80395059025453.\n",
      "The current iteration of k-means is: 30,                the average loss is 111.80277929995395.\n",
      "The current iteration of k-means is: 31,                the average loss is 111.80223212442833.\n",
      "For k= 11 :\n",
      "The current iteration of k-means is: 0,                the average loss is 333.25101297421935.\n",
      "The current iteration of k-means is: 1,                the average loss is 119.52516970123474.\n",
      "The current iteration of k-means is: 2,                the average loss is 114.68099409181785.\n",
      "The current iteration of k-means is: 3,                the average loss is 112.96456946196547.\n",
      "The current iteration of k-means is: 4,                the average loss is 112.29705963585127.\n",
      "The current iteration of k-means is: 5,                the average loss is 111.98974766645867.\n",
      "The current iteration of k-means is: 6,                the average loss is 111.80772683141639.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 7,                the average loss is 111.69855818771902.\n",
      "The current iteration of k-means is: 8,                the average loss is 111.627688541022.\n",
      "The current iteration of k-means is: 9,                the average loss is 111.56553361154441.\n",
      "The current iteration of k-means is: 10,                the average loss is 111.52681911443223.\n",
      "The current iteration of k-means is: 11,                the average loss is 111.49978704077411.\n",
      "The current iteration of k-means is: 12,                the average loss is 111.47918316813893.\n",
      "The current iteration of k-means is: 13,                the average loss is 111.46488333809955.\n",
      "The current iteration of k-means is: 14,                the average loss is 111.45356448376333.\n",
      "The current iteration of k-means is: 15,                the average loss is 111.44473786856555.\n",
      "The current iteration of k-means is: 16,                the average loss is 111.43641199907977.\n",
      "The current iteration of k-means is: 17,                the average loss is 111.42900613696634.\n",
      "The current iteration of k-means is: 18,                the average loss is 111.4210112889715.\n",
      "The current iteration of k-means is: 19,                the average loss is 111.41691301102475.\n",
      "The current iteration of k-means is: 20,                the average loss is 111.41213870363454.\n",
      "The current iteration of k-means is: 21,                the average loss is 111.40650158325401.\n",
      "The current iteration of k-means is: 22,                the average loss is 111.40034345077241.\n",
      "The current iteration of k-means is: 23,                the average loss is 111.39478921723824.\n",
      "The current iteration of k-means is: 24,                the average loss is 111.38874299045673.\n",
      "The current iteration of k-means is: 25,                the average loss is 111.38468939790954.\n",
      "The current iteration of k-means is: 26,                the average loss is 111.38046995164203.\n",
      "The current iteration of k-means is: 27,                the average loss is 111.3777545650606.\n",
      "The current iteration of k-means is: 28,                the average loss is 111.37362706587699.\n",
      "The current iteration of k-means is: 29,                the average loss is 111.37183721764904.\n",
      "The current iteration of k-means is: 30,                the average loss is 111.36859772184901.\n",
      "The current iteration of k-means is: 31,                the average loss is 111.36684571425329.\n",
      "The current iteration of k-means is: 32,                the average loss is 111.36554761535777.\n",
      "The current iteration of k-means is: 33,                the average loss is 111.36487117780496.\n",
      "For k= 12 :\n",
      "The current iteration of k-means is: 0,                the average loss is 338.70126020435725.\n",
      "The current iteration of k-means is: 1,                the average loss is 119.27998789132137.\n",
      "The current iteration of k-means is: 2,                the average loss is 114.41776368421803.\n",
      "The current iteration of k-means is: 3,                the average loss is 112.85253326092926.\n",
      "The current iteration of k-means is: 4,                the average loss is 112.260955739928.\n",
      "The current iteration of k-means is: 5,                the average loss is 111.94747165579481.\n",
      "The current iteration of k-means is: 6,                the average loss is 111.7396316859256.\n",
      "The current iteration of k-means is: 7,                the average loss is 111.6103292339359.\n",
      "The current iteration of k-means is: 8,                the average loss is 111.52074860278312.\n",
      "The current iteration of k-means is: 9,                the average loss is 111.45679031017572.\n",
      "The current iteration of k-means is: 10,                the average loss is 111.40634386724206.\n",
      "The current iteration of k-means is: 11,                the average loss is 111.36984530864981.\n",
      "The current iteration of k-means is: 12,                the average loss is 111.33900792059822.\n",
      "The current iteration of k-means is: 13,                the average loss is 111.31747772597768.\n",
      "The current iteration of k-means is: 14,                the average loss is 111.30395252328066.\n",
      "The current iteration of k-means is: 15,                the average loss is 111.29446944510269.\n",
      "The current iteration of k-means is: 16,                the average loss is 111.28702755410627.\n",
      "The current iteration of k-means is: 17,                the average loss is 111.28137206869447.\n",
      "The current iteration of k-means is: 18,                the average loss is 111.27735841330355.\n",
      "The current iteration of k-means is: 19,                the average loss is 111.27441683771447.\n",
      "The current iteration of k-means is: 20,                the average loss is 111.27138912827792.\n",
      "The current iteration of k-means is: 21,                the average loss is 111.26869002740862.\n",
      "The current iteration of k-means is: 22,                the average loss is 111.2646230985242.\n",
      "The current iteration of k-means is: 23,                the average loss is 111.26069723149192.\n",
      "The current iteration of k-means is: 24,                the average loss is 111.25710831137698.\n",
      "The current iteration of k-means is: 25,                the average loss is 111.2516727501017.\n",
      "The current iteration of k-means is: 26,                the average loss is 111.24797470434811.\n",
      "The current iteration of k-means is: 27,                the average loss is 111.24388769311355.\n",
      "The current iteration of k-means is: 28,                the average loss is 111.23937301292979.\n",
      "The current iteration of k-means is: 29,                the average loss is 111.23648685017896.\n",
      "The current iteration of k-means is: 30,                the average loss is 111.23500755258529.\n",
      "The current iteration of k-means is: 31,                the average loss is 111.23294230064195.\n",
      "The current iteration of k-means is: 32,                the average loss is 111.22974874598435.\n",
      "The current iteration of k-means is: 33,                the average loss is 111.22806964084981.\n",
      "The current iteration of k-means is: 34,                the average loss is 111.22718825833273.\n",
      "For k= 13 :\n",
      "The current iteration of k-means is: 0,                the average loss is 335.8868479737125.\n",
      "The current iteration of k-means is: 1,                the average loss is 118.86866144540932.\n",
      "The current iteration of k-means is: 2,                the average loss is 114.25220666391314.\n",
      "The current iteration of k-means is: 3,                the average loss is 112.88380871032379.\n",
      "The current iteration of k-means is: 4,                the average loss is 112.24050062831319.\n",
      "The current iteration of k-means is: 5,                the average loss is 111.85877828826764.\n",
      "The current iteration of k-means is: 6,                the average loss is 111.64890702163295.\n",
      "The current iteration of k-means is: 7,                the average loss is 111.51683916337474.\n",
      "The current iteration of k-means is: 8,                the average loss is 111.43184721509057.\n",
      "The current iteration of k-means is: 9,                the average loss is 111.3685346464552.\n",
      "The current iteration of k-means is: 10,                the average loss is 111.30710092311756.\n",
      "The current iteration of k-means is: 11,                the average loss is 111.26116311969407.\n",
      "The current iteration of k-means is: 12,                the average loss is 111.22618814050267.\n",
      "The current iteration of k-means is: 13,                the average loss is 111.19986369368098.\n",
      "The current iteration of k-means is: 14,                the average loss is 111.18222005198434.\n",
      "The current iteration of k-means is: 15,                the average loss is 111.16190426659774.\n",
      "The current iteration of k-means is: 16,                the average loss is 111.14342871280711.\n",
      "The current iteration of k-means is: 17,                the average loss is 111.13532039462098.\n",
      "The current iteration of k-means is: 18,                the average loss is 111.12957888495741.\n",
      "The current iteration of k-means is: 19,                the average loss is 111.12253779520178.\n",
      "The current iteration of k-means is: 20,                the average loss is 111.11898053026162.\n",
      "The current iteration of k-means is: 21,                the average loss is 111.11510099376856.\n",
      "The current iteration of k-means is: 22,                the average loss is 111.1105495045399.\n",
      "The current iteration of k-means is: 23,                the average loss is 111.10778367824636.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 24,                the average loss is 111.10266902899757.\n",
      "The current iteration of k-means is: 25,                the average loss is 111.09843171169359.\n",
      "The current iteration of k-means is: 26,                the average loss is 111.09483174715966.\n",
      "The current iteration of k-means is: 27,                the average loss is 111.09118581451116.\n",
      "The current iteration of k-means is: 28,                the average loss is 111.08667394864587.\n",
      "The current iteration of k-means is: 29,                the average loss is 111.08262380648728.\n",
      "The current iteration of k-means is: 30,                the average loss is 111.07916208810835.\n",
      "The current iteration of k-means is: 31,                the average loss is 111.07743560976854.\n",
      "The current iteration of k-means is: 32,                the average loss is 111.07350761206885.\n",
      "The current iteration of k-means is: 33,                the average loss is 111.07071709848063.\n",
      "The current iteration of k-means is: 34,                the average loss is 111.06967940717703.\n",
      "The current iteration of k-means is: 35,                the average loss is 111.06938726329166.\n",
      "For k= 14 :\n",
      "The current iteration of k-means is: 0,                the average loss is 335.7637012599359.\n",
      "The current iteration of k-means is: 1,                the average loss is 118.65542069010046.\n",
      "The current iteration of k-means is: 2,                the average loss is 113.6952789125567.\n",
      "The current iteration of k-means is: 3,                the average loss is 112.09855875891672.\n",
      "The current iteration of k-means is: 4,                the average loss is 111.40655006299826.\n",
      "The current iteration of k-means is: 5,                the average loss is 111.08180111795619.\n",
      "The current iteration of k-means is: 6,                the average loss is 110.91555870151028.\n",
      "The current iteration of k-means is: 7,                the average loss is 110.82257958341641.\n",
      "The current iteration of k-means is: 8,                the average loss is 110.76501242585248.\n",
      "The current iteration of k-means is: 9,                the average loss is 110.72301579625797.\n",
      "The current iteration of k-means is: 10,                the average loss is 110.68949408785552.\n",
      "The current iteration of k-means is: 11,                the average loss is 110.66666548098847.\n",
      "The current iteration of k-means is: 12,                the average loss is 110.64656375190201.\n",
      "The current iteration of k-means is: 13,                the average loss is 110.63378690200913.\n",
      "The current iteration of k-means is: 14,                the average loss is 110.6214288941869.\n",
      "The current iteration of k-means is: 15,                the average loss is 110.6108006741392.\n",
      "The current iteration of k-means is: 16,                the average loss is 110.60105095702147.\n",
      "The current iteration of k-means is: 17,                the average loss is 110.59500172312569.\n",
      "The current iteration of k-means is: 18,                the average loss is 110.59064156572404.\n",
      "The current iteration of k-means is: 19,                the average loss is 110.58517523610843.\n",
      "The current iteration of k-means is: 20,                the average loss is 110.5802020760714.\n",
      "The current iteration of k-means is: 21,                the average loss is 110.5765841830723.\n",
      "The current iteration of k-means is: 22,                the average loss is 110.57444592820777.\n",
      "The current iteration of k-means is: 23,                the average loss is 110.57327377446536.\n",
      "The current iteration of k-means is: 24,                the average loss is 110.56975786701597.\n",
      "The current iteration of k-means is: 25,                the average loss is 110.5670012888087.\n",
      "The current iteration of k-means is: 26,                the average loss is 110.56370545190363.\n",
      "The current iteration of k-means is: 27,                the average loss is 110.56163505380876.\n",
      "The current iteration of k-means is: 28,                the average loss is 110.55965237893847.\n",
      "The current iteration of k-means is: 29,                the average loss is 110.55839417459616.\n",
      "The current iteration of k-means is: 30,                the average loss is 110.55824302260145.\n",
      "For k= 15 :\n",
      "The current iteration of k-means is: 0,                the average loss is 332.6475143874581.\n",
      "The current iteration of k-means is: 1,                the average loss is 118.38449643547055.\n",
      "The current iteration of k-means is: 2,                the average loss is 113.50511588680548.\n",
      "The current iteration of k-means is: 3,                the average loss is 112.25936685901769.\n",
      "The current iteration of k-means is: 4,                the average loss is 111.73491497162264.\n",
      "The current iteration of k-means is: 5,                the average loss is 111.4221336951525.\n",
      "The current iteration of k-means is: 6,                the average loss is 111.20386172221815.\n",
      "The current iteration of k-means is: 7,                the average loss is 111.05177899809063.\n",
      "The current iteration of k-means is: 8,                the average loss is 110.94533628350585.\n",
      "The current iteration of k-means is: 9,                the average loss is 110.86196425216359.\n",
      "The current iteration of k-means is: 10,                the average loss is 110.79247016908687.\n",
      "The current iteration of k-means is: 11,                the average loss is 110.74652091099018.\n",
      "The current iteration of k-means is: 12,                the average loss is 110.7149975478847.\n",
      "The current iteration of k-means is: 13,                the average loss is 110.69343900666895.\n",
      "The current iteration of k-means is: 14,                the average loss is 110.677863417859.\n",
      "The current iteration of k-means is: 15,                the average loss is 110.66539859121426.\n",
      "The current iteration of k-means is: 16,                the average loss is 110.65511408700058.\n",
      "The current iteration of k-means is: 17,                the average loss is 110.64709879163729.\n",
      "The current iteration of k-means is: 18,                the average loss is 110.64225008841133.\n",
      "The current iteration of k-means is: 19,                the average loss is 110.63999298267937.\n",
      "The current iteration of k-means is: 20,                the average loss is 110.6379231984199.\n",
      "The current iteration of k-means is: 21,                the average loss is 110.63651012385904.\n",
      "The current iteration of k-means is: 22,                the average loss is 110.63268215853333.\n",
      "The current iteration of k-means is: 23,                the average loss is 110.62816483975946.\n",
      "The current iteration of k-means is: 24,                the average loss is 110.62378123799395.\n",
      "The current iteration of k-means is: 25,                the average loss is 110.62116488482677.\n",
      "The current iteration of k-means is: 26,                the average loss is 110.61864982808254.\n",
      "The current iteration of k-means is: 27,                the average loss is 110.61627301022455.\n",
      "The current iteration of k-means is: 28,                the average loss is 110.6139636445157.\n",
      "The current iteration of k-means is: 29,                the average loss is 110.61169451687066.\n",
      "The current iteration of k-means is: 30,                the average loss is 110.61021574677872.\n",
      "The current iteration of k-means is: 31,                the average loss is 110.60921619618111.\n",
      "For k= 16 :\n",
      "The current iteration of k-means is: 0,                the average loss is 325.15309878441883.\n",
      "The current iteration of k-means is: 1,                the average loss is 118.51856001289063.\n",
      "The current iteration of k-means is: 2,                the average loss is 113.64641418354924.\n",
      "The current iteration of k-means is: 3,                the average loss is 111.92316772188025.\n",
      "The current iteration of k-means is: 4,                the average loss is 111.21203050210117.\n",
      "The current iteration of k-means is: 5,                the average loss is 110.8509547004761.\n",
      "The current iteration of k-means is: 6,                the average loss is 110.64050522006117.\n",
      "The current iteration of k-means is: 7,                the average loss is 110.51449237700416.\n",
      "The current iteration of k-means is: 8,                the average loss is 110.42985378665263.\n",
      "The current iteration of k-means is: 9,                the average loss is 110.37959451730516.\n",
      "The current iteration of k-means is: 10,                the average loss is 110.3434432690442.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 11,                the average loss is 110.31532449039801.\n",
      "The current iteration of k-means is: 12,                the average loss is 110.2969344138432.\n",
      "The current iteration of k-means is: 13,                the average loss is 110.28210747968582.\n",
      "The current iteration of k-means is: 14,                the average loss is 110.27601638298701.\n",
      "The current iteration of k-means is: 15,                the average loss is 110.26990140281625.\n",
      "The current iteration of k-means is: 16,                the average loss is 110.26229504456762.\n",
      "The current iteration of k-means is: 17,                the average loss is 110.2568023386958.\n",
      "The current iteration of k-means is: 18,                the average loss is 110.24995169812208.\n",
      "The current iteration of k-means is: 19,                the average loss is 110.24421785278591.\n",
      "The current iteration of k-means is: 20,                the average loss is 110.24082529693271.\n",
      "The current iteration of k-means is: 21,                the average loss is 110.23688428631583.\n",
      "The current iteration of k-means is: 22,                the average loss is 110.23416355335401.\n",
      "The current iteration of k-means is: 23,                the average loss is 110.23066057124639.\n",
      "The current iteration of k-means is: 24,                the average loss is 110.22752474481878.\n",
      "The current iteration of k-means is: 25,                the average loss is 110.22577812586648.\n",
      "The current iteration of k-means is: 26,                the average loss is 110.22347683038109.\n",
      "The current iteration of k-means is: 27,                the average loss is 110.22160367784784.\n",
      "The current iteration of k-means is: 28,                the average loss is 110.22120334152673.\n",
      "For k= 17 :\n",
      "The current iteration of k-means is: 0,                the average loss is 323.0155054755088.\n",
      "The current iteration of k-means is: 1,                the average loss is 117.97971180773462.\n",
      "The current iteration of k-means is: 2,                the average loss is 113.49302700431666.\n",
      "The current iteration of k-means is: 3,                the average loss is 112.2569911718532.\n",
      "The current iteration of k-means is: 4,                the average loss is 111.62595360083185.\n",
      "The current iteration of k-means is: 5,                the average loss is 111.24242836881425.\n",
      "The current iteration of k-means is: 6,                the average loss is 110.98283124386862.\n",
      "The current iteration of k-means is: 7,                the average loss is 110.80408550517026.\n",
      "The current iteration of k-means is: 8,                the average loss is 110.687973551759.\n",
      "The current iteration of k-means is: 9,                the average loss is 110.58298093706001.\n",
      "The current iteration of k-means is: 10,                the average loss is 110.49178172345026.\n",
      "The current iteration of k-means is: 11,                the average loss is 110.422019758677.\n",
      "The current iteration of k-means is: 12,                the average loss is 110.37777871648215.\n",
      "The current iteration of k-means is: 13,                the average loss is 110.34861954639163.\n",
      "The current iteration of k-means is: 14,                the average loss is 110.31834171975588.\n",
      "The current iteration of k-means is: 15,                the average loss is 110.2920274311607.\n",
      "The current iteration of k-means is: 16,                the average loss is 110.267888164093.\n",
      "The current iteration of k-means is: 17,                the average loss is 110.24690539537151.\n",
      "The current iteration of k-means is: 18,                the average loss is 110.22658092360884.\n",
      "The current iteration of k-means is: 19,                the average loss is 110.20950789629735.\n",
      "The current iteration of k-means is: 20,                the average loss is 110.18915137171408.\n",
      "The current iteration of k-means is: 21,                the average loss is 110.17111277928512.\n",
      "The current iteration of k-means is: 22,                the average loss is 110.1564224641718.\n",
      "The current iteration of k-means is: 23,                the average loss is 110.13249131754439.\n",
      "The current iteration of k-means is: 24,                the average loss is 110.11517020634608.\n",
      "The current iteration of k-means is: 25,                the average loss is 110.10291729643706.\n",
      "The current iteration of k-means is: 26,                the average loss is 110.09657219386446.\n",
      "The current iteration of k-means is: 27,                the average loss is 110.09227417392994.\n",
      "The current iteration of k-means is: 28,                the average loss is 110.08866094667086.\n",
      "The current iteration of k-means is: 29,                the average loss is 110.08610522478617.\n",
      "The current iteration of k-means is: 30,                the average loss is 110.08311718119496.\n",
      "The current iteration of k-means is: 31,                the average loss is 110.08173588545324.\n",
      "The current iteration of k-means is: 32,                the average loss is 110.0794945097332.\n",
      "The current iteration of k-means is: 33,                the average loss is 110.07672170479141.\n",
      "The current iteration of k-means is: 34,                the average loss is 110.07494461909461.\n",
      "The current iteration of k-means is: 35,                the average loss is 110.07399194477385.\n",
      "For k= 18 :\n",
      "The current iteration of k-means is: 0,                the average loss is 326.920011038296.\n",
      "The current iteration of k-means is: 1,                the average loss is 118.37564858344558.\n",
      "The current iteration of k-means is: 2,                the average loss is 113.15208247175414.\n",
      "The current iteration of k-means is: 3,                the average loss is 111.31488753379001.\n",
      "The current iteration of k-means is: 4,                the average loss is 110.68229121431983.\n",
      "The current iteration of k-means is: 5,                the average loss is 110.35709341734268.\n",
      "The current iteration of k-means is: 6,                the average loss is 110.17510719333184.\n",
      "The current iteration of k-means is: 7,                the average loss is 110.06070411521736.\n",
      "The current iteration of k-means is: 8,                the average loss is 109.97402895754053.\n",
      "The current iteration of k-means is: 9,                the average loss is 109.91305022258304.\n",
      "The current iteration of k-means is: 10,                the average loss is 109.87453075767145.\n",
      "The current iteration of k-means is: 11,                the average loss is 109.85162666045949.\n",
      "The current iteration of k-means is: 12,                the average loss is 109.83312380650737.\n",
      "The current iteration of k-means is: 13,                the average loss is 109.82242262509477.\n",
      "The current iteration of k-means is: 14,                the average loss is 109.8126435274741.\n",
      "The current iteration of k-means is: 15,                the average loss is 109.80622563497536.\n",
      "The current iteration of k-means is: 16,                the average loss is 109.79965983760616.\n",
      "The current iteration of k-means is: 17,                the average loss is 109.79204889739303.\n",
      "The current iteration of k-means is: 18,                the average loss is 109.7870691931401.\n",
      "The current iteration of k-means is: 19,                the average loss is 109.78341716715191.\n",
      "The current iteration of k-means is: 20,                the average loss is 109.780459004124.\n",
      "The current iteration of k-means is: 21,                the average loss is 109.77685286936965.\n",
      "The current iteration of k-means is: 22,                the average loss is 109.77480042880084.\n",
      "The current iteration of k-means is: 23,                the average loss is 109.7731519312424.\n",
      "The current iteration of k-means is: 24,                the average loss is 109.77237532489502.\n",
      "For k= 19 :\n",
      "The current iteration of k-means is: 0,                the average loss is 325.203264971926.\n",
      "The current iteration of k-means is: 1,                the average loss is 117.77016232453035.\n",
      "The current iteration of k-means is: 2,                the average loss is 112.89805186157402.\n",
      "The current iteration of k-means is: 3,                the average loss is 111.40761294567636.\n",
      "The current iteration of k-means is: 4,                the average loss is 110.86383571743583.\n",
      "The current iteration of k-means is: 5,                the average loss is 110.5774695145667.\n",
      "The current iteration of k-means is: 6,                the average loss is 110.37734931041538.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 7,                the average loss is 110.247887526559.\n",
      "The current iteration of k-means is: 8,                the average loss is 110.15141498558334.\n",
      "The current iteration of k-means is: 9,                the average loss is 110.08577114746505.\n",
      "The current iteration of k-means is: 10,                the average loss is 110.02519467810896.\n",
      "The current iteration of k-means is: 11,                the average loss is 109.9784098907263.\n",
      "The current iteration of k-means is: 12,                the average loss is 109.94124388726523.\n",
      "The current iteration of k-means is: 13,                the average loss is 109.89678223756698.\n",
      "The current iteration of k-means is: 14,                the average loss is 109.86826721281992.\n",
      "The current iteration of k-means is: 15,                the average loss is 109.84936852164026.\n",
      "The current iteration of k-means is: 16,                the average loss is 109.83250976400974.\n",
      "The current iteration of k-means is: 17,                the average loss is 109.81860610934638.\n",
      "The current iteration of k-means is: 18,                the average loss is 109.80439347660446.\n",
      "The current iteration of k-means is: 19,                the average loss is 109.79635422248866.\n",
      "The current iteration of k-means is: 20,                the average loss is 109.79064073768932.\n",
      "The current iteration of k-means is: 21,                the average loss is 109.78837022546035.\n",
      "The current iteration of k-means is: 22,                the average loss is 109.78573548418856.\n",
      "The current iteration of k-means is: 23,                the average loss is 109.78507448688632.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26d9eee1470>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Defining the parameters\n",
    "k = 20\n",
    "max_iters = 100\n",
    "threshold = 1e-3\n",
    "#Grid-searching the number of clusters (by 100s)\n",
    "losses=[]\n",
    "for i in range(1,k):\n",
    "    print('For k=',i,':')\n",
    "    losses.append(kmeans(cli_vs_mov, i, max_iters, threshold)[2])\n",
    "plt.plot(range(1,k),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 0,                the average loss is 338.2407241814187.\n",
      "The current iteration of k-means is: 1,                the average loss is 120.31189821145902.\n",
      "The current iteration of k-means is: 2,                the average loss is 115.15645933244026.\n",
      "The current iteration of k-means is: 3,                the average loss is 113.68345749307282.\n",
      "The current iteration of k-means is: 4,                the average loss is 113.16677041238654.\n",
      "The current iteration of k-means is: 5,                the average loss is 112.9057024604105.\n",
      "The current iteration of k-means is: 6,                the average loss is 112.76084401761214.\n",
      "The current iteration of k-means is: 7,                the average loss is 112.65460022905452.\n",
      "The current iteration of k-means is: 8,                the average loss is 112.5815918991939.\n",
      "The current iteration of k-means is: 9,                the average loss is 112.5185892772096.\n",
      "The current iteration of k-means is: 10,                the average loss is 112.47528425742169.\n",
      "The current iteration of k-means is: 11,                the average loss is 112.44348899683128.\n",
      "The current iteration of k-means is: 12,                the average loss is 112.4215078801549.\n",
      "The current iteration of k-means is: 13,                the average loss is 112.40276699338622.\n",
      "The current iteration of k-means is: 14,                the average loss is 112.38983078948215.\n",
      "The current iteration of k-means is: 15,                the average loss is 112.37912744633995.\n",
      "The current iteration of k-means is: 16,                the average loss is 112.37025359486604.\n",
      "The current iteration of k-means is: 17,                the average loss is 112.36249549471233.\n",
      "The current iteration of k-means is: 18,                the average loss is 112.35730544789618.\n",
      "The current iteration of k-means is: 19,                the average loss is 112.35082446043312.\n",
      "The current iteration of k-means is: 20,                the average loss is 112.34485831052363.\n",
      "The current iteration of k-means is: 21,                the average loss is 112.34090876170332.\n",
      "The current iteration of k-means is: 22,                the average loss is 112.33797879198407.\n",
      "The current iteration of k-means is: 23,                the average loss is 112.33626467653767.\n",
      "The current iteration of k-means is: 24,                the average loss is 112.33537510695322.\n",
      "The current iteration of k-means is: 25,                the average loss is 112.3337895549338.\n",
      "The current iteration of k-means is: 26,                the average loss is 112.33207547722515.\n",
      "The current iteration of k-means is: 27,                the average loss is 112.32900197950522.\n",
      "The current iteration of k-means is: 28,                the average loss is 112.32594052142258.\n",
      "The current iteration of k-means is: 29,                the average loss is 112.32352677645262.\n",
      "The current iteration of k-means is: 30,                the average loss is 112.32213557773065.\n",
      "The current iteration of k-means is: 31,                the average loss is 112.32151364573548.\n",
      "The current iteration of k-means is: 32,                the average loss is 112.32061819037199.\n",
      "The current iteration of k-means is: 33,                the average loss is 112.31866073684944.\n",
      "The current iteration of k-means is: 34,                the average loss is 112.31671161443927.\n",
      "The current iteration of k-means is: 35,                the average loss is 112.31492516251546.\n",
      "The current iteration of k-means is: 36,                the average loss is 112.3118513436122.\n",
      "The current iteration of k-means is: 37,                the average loss is 112.3089663608891.\n",
      "The current iteration of k-means is: 38,                the average loss is 112.30692846638519.\n",
      "The current iteration of k-means is: 39,                the average loss is 112.3065680200551.\n",
      "The current iteration of k-means is: 40,                the average loss is 112.30584408610724.\n",
      "The current iteration of k-means is: 41,                the average loss is 112.30531550573116.\n",
      "The current iteration of k-means is: 42,                the average loss is 112.3046489854169.\n",
      "The current iteration of k-means is: 43,                the average loss is 112.30413950486658.\n",
      "The current iteration of k-means is: 44,                the average loss is 112.30345885600146.\n",
      "The current iteration of k-means is: 45,                the average loss is 112.3020964881782.\n",
      "The current iteration of k-means is: 46,                the average loss is 112.30164119196553.\n",
      "The current iteration of k-means is: 47,                the average loss is 112.30164119196553.\n"
     ]
    }
   ],
   "source": [
    "#k chosen using the above plots\n",
    "k_opt=9\n",
    "#Defining the parameters\n",
    "max_iters = 100\n",
    "threshold = 1e-6\n",
    "#Computing clusters of similar users\n",
    "assignments, mu, _=kmeans(cli_vs_mov, k_opt, max_iters, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Cluster Aggregation Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Col</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Col      1   10  100  1000  101  102  103  104  105  106 ...   990  991  992  \\\n",
       "Row                                                      ...                   \n",
       "1      3.0  5.0  4.0   4.0  3.0  4.0  3.0  2.0  3.0  3.0 ...   2.0  3.0  4.0   \n",
       "10     4.0  3.0  3.0   4.0  4.0  4.0  3.0  3.0  3.0  4.0 ...   3.0  3.0  3.0   \n",
       "100    3.0  5.0  3.0   3.0  5.0  4.0  3.0  2.0  2.0  4.0 ...   3.0  2.0  3.0   \n",
       "1000   4.0  2.0  4.0   2.0  5.0  5.0  4.0  3.0  4.0  4.0 ...   4.0  3.0  4.0   \n",
       "10000  3.0  4.0  4.0   3.0  4.0  4.0  3.0  3.0  3.0  3.0 ...   3.0  2.0  4.0   \n",
       "\n",
       "Col    993  994  995  996  997  998  999  \n",
       "Row                                       \n",
       "1      3.0  3.0  4.0  3.0  3.0  3.0  3.0  \n",
       "10     3.0  4.0  5.0  4.0  4.0  3.0  3.0  \n",
       "100    2.0  3.0  1.0  3.0  3.0  2.0  3.0  \n",
       "1000   2.0  4.0  5.0  1.0  4.0  2.0  3.0  \n",
       "10000  3.0  3.0  3.0  3.0  3.0  4.0  3.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating a prediction using the clusters of similar users\n",
    "classified=cli_vs_mov.copy()\n",
    "mu_rounded=np.round(mu)\n",
    "for i in range(k_opt):\n",
    "    classified[assignments==i]=np.where(np.isnan(classified[assignments==i]),mu_rounded[i],classified[assignments==i])\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Col</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Col      1   10  100  1000  101  102  103  104  105  106 ...   990  991  992  \\\n",
       "Row                                                      ...                   \n",
       "1      3.0  5.0  3.0   4.0  3.0  4.0  3.0  2.0  3.0  3.0 ...   2.0  3.0  4.0   \n",
       "10     3.0  3.0  3.0   4.0  3.0  5.0  3.0  2.0  3.0  5.0 ...   3.0  3.0  4.0   \n",
       "100    2.0  5.0  3.0   3.0  5.0  4.0  3.0  2.0  2.0  4.0 ...   2.0  2.0  3.0   \n",
       "1000   4.0  2.0  4.0   2.0  5.0  5.0  4.0  3.0  4.0  5.0 ...   4.0  3.0  4.0   \n",
       "10000  4.0  4.0  3.0   3.0  4.0  4.0  3.0  2.0  3.0  3.0 ...   3.0  2.0  4.0   \n",
       "\n",
       "Col    993  994  995  996  997  998  999  \n",
       "Row                                       \n",
       "1      3.0  3.0  4.0  3.0  3.0  3.0  3.0  \n",
       "10     2.0  3.0  5.0  4.0  4.0  3.0  3.0  \n",
       "100    1.0  2.0  1.0  3.0  3.0  3.0  3.0  \n",
       "1000   2.0  4.0  5.0  1.0  4.0  2.0  3.0  \n",
       "10000  2.0  3.0  3.0  3.0  3.0  4.0  3.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating a prediction using the median of the scores of similar users\n",
    "classified=cli_vs_mov.copy()\n",
    "median=np.nanmedian(classified,0)[np.newaxis,:]\n",
    "for i in range(k_opt):\n",
    "    median_k=np.rint(np.nanmedian(np.concatenate((classified[assignments==i],median),0),0))\n",
    "    classified[assignments==i]=np.where(np.isnan(classified[assignments==i]),median_k,classified[assignments==i])\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Col</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Col      1   10  100  1000  101  102  103  104  105  106 ...   990  991  992  \\\n",
       "Row                                                      ...                   \n",
       "1      4.0  5.0  4.0   4.0  3.0  5.0  3.0  2.0  3.0  3.0 ...   4.0  3.0  4.0   \n",
       "10     4.0  3.0  3.0   3.0  4.0  5.0  3.0  3.0  3.0  5.0 ...   3.0  3.0  4.0   \n",
       "100    2.0  5.0  3.0   3.0  5.0  5.0  3.0  2.0  2.0  5.0 ...   2.0  1.0  3.0   \n",
       "1000   4.0  2.0  4.0   2.0  5.0  5.0  3.0  3.0  4.0  5.0 ...   5.0  3.0  4.0   \n",
       "10000  4.0  4.0  4.0   3.0  3.0  5.0  3.0  2.0  3.0  3.0 ...   4.0  2.0  4.0   \n",
       "\n",
       "Col    993  994  995  996  997  998  999  \n",
       "Row                                       \n",
       "1      1.0  3.0  3.0  3.0  3.0  4.0  4.0  \n",
       "10     4.0  3.0  5.0  3.0  4.0  4.0  3.0  \n",
       "100    1.0  3.0  1.0  3.0  3.0  3.0  2.0  \n",
       "1000   2.0  4.0  5.0  1.0  5.0  2.0  3.0  \n",
       "10000  1.0  3.0  3.0  3.0  3.0  4.0  4.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generating a prediction using the most frequent score among similar users\n",
    "classified=cli_vs_mov.copy()\n",
    "top_freq=most_common(classified)\n",
    "for i in range(k_opt):\n",
    "    top_freq_k=most_common(classified[assignments==i])\n",
    "    top_freq_k=np.where(np.isnan(top_freq_k),top_freq,top_freq_k)\n",
    "    classified[assignments==i]=np.where(np.isnan(classified[assignments==i]),top_freq_k,classified[assignments==i])\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>Col</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Row Col  Rating\n",
       "0      1   1     3.0\n",
       "1     10   1     4.0\n",
       "2    100   1     3.0\n",
       "3   1000   1     4.0\n",
       "4  10000   1     3.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the columns back to the Col column and making Row a column instead of an index\n",
    "classified=pd.melt(classified.reset_index(), id_vars=['Row'], var_name='Col', value_name='Rating')\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1_c1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r10_c1</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r100_c1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1000_c1</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r10000_c1</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rating\n",
       "r1_c1         3.0\n",
       "r10_c1        4.0\n",
       "r100_c1       3.0\n",
       "r1000_c1      4.0\n",
       "r10000_c1     3.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting Row and Col values into an id\n",
    "classified.index='r'+classified['Row']+'_c'+classified['Col']\n",
    "classified=classified.drop(columns=['Row','Col'])\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r37_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r73_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r156_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r160_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r248_c1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Prediction\n",
       "0   r37_c1           3\n",
       "1   r73_c1           3\n",
       "2  r156_c1           3\n",
       "3  r160_c1           3\n",
       "4  r248_c1           3"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the sample submission data\n",
    "sample_sumbission=pd.read_csv('sampleSubmission.csv')\n",
    "sample_sumbission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1000_c1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r1141_c1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r1146_c1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1157_c1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r1184_c1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Prediction\n",
       "0  r1000_c1         4.0\n",
       "1  r1141_c1         4.0\n",
       "2  r1146_c1         4.0\n",
       "3  r1157_c1         2.0\n",
       "4  r1184_c1         4.0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified=classified[classified.index.isin(list(sample_sumbission['Id']))].reset_index().rename(columns={'index': 'Id', 'Rating':'Prediction'})\n",
    "classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the predictions\n",
    "classified.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
